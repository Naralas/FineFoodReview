{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Food Review\n",
    "\n",
    "Ludovic Herbelin, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goals : Predict review score from the text of the review.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 rows in data\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = 'Reviews.csv'\n",
    "N_ROWS = 60000\n",
    "\n",
    "dataset = pd.read_csv(DATASET_PATH, nrows=N_ROWS)\n",
    "\n",
    "print(f\"{len(dataset)} rows in data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Not as Advertised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Cough Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Great taffy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score                Summary\n",
       "0                     1                       1      5  Good Quality Dog Food\n",
       "1                     0                       0      1      Not as Advertised\n",
       "2                     1                       1      4  \"Delight\" says it all\n",
       "3                     3                       3      2         Cough Medicine\n",
       "4                     0                       0      5            Great taffy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.copy()\n",
    "df = df.drop(columns=['Id','ProductId', 'UserId', 'ProfileName', 'Time', 'Text'])\n",
    "feature_column = 'Summary'\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the neutral reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depending on our goals we might want to remove neutral reviews (IE score of 3)\n",
    "REMOVE_NEUTRAL = False\n",
    "\n",
    "if REMOVE_NEUTRAL:\n",
    "    df = df[df.Score != 3]\n",
    "    print(f\"{len(df)} rows left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'Score']\n",
    "Y = df['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size : 47998, test set size : 12000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify=Y, train_size=TRAIN_RATIO, random_state=42)\n",
    "\n",
    "print(f\"Train size : {len(Y_train)}, test set size : {len(Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing\n",
    "\n",
    "Helper class for preprocessing the text : remove stopwords, punctuation etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good qualiti dog food\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ludovic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ludovic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "class TextProcessor:\n",
    "    def __init__(self, language='english', remove_stopwords = True, perform_stemming = True):\n",
    "        \"\"\" init functions, load the stopwords and punkt for tokenizer\n",
    "        Keywords args :\n",
    "        language -- 'english' or other\n",
    "        remove_stopwords -- If true, will perform stopwords removal\n",
    "        perform_stemming -- If true, will stem the words\n",
    "        \"\"\"\n",
    "        nltk.download('stopwords')\n",
    "        nltk.download('punkt')\n",
    "        self.perform_stemming = perform_stemming\n",
    "        if(self.perform_stemming):\n",
    "            self.stemmer = SnowballStemmer(language)\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        if(self.remove_stopwords):\n",
    "            self.stopwords = set(stopwords.words(language))  \n",
    "\n",
    "    def __stem_word__(self, word):\n",
    "        return self.stemmer.stem(word)\n",
    "\n",
    "    def __tokenize_text__(self, text):\n",
    "        return word_tokenize(text)\n",
    "\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Set the words in the text to lowercase, remove the stop words and punctuation if set to true at init\"\"\"\n",
    "        words = self.__tokenize_text__(text)\n",
    "        \n",
    "        # set words to lowercase and remove punctuation\n",
    "        words = [word.lower() for word in words if word.isalpha()]\n",
    "        if self.perform_stemming:\n",
    "            words = [self.__stem_word__(word) for word in words]\n",
    "        if self.remove_stopwords:\n",
    "            words = list(filter(lambda w: w not in self.stopwords, words))\n",
    "        \n",
    "        return ' '.join(words)\n",
    "\n",
    "tp = TextProcessor(remove_stopwords=True, perform_stemming=True)\n",
    "print(tp.preprocess_text(df[feature_column][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\documents\\school\\swisscom_assignment\\finefoodreview\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:659: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[k] = np.nan\n",
      "e:\\documents\\school\\swisscom_assignment\\finefoodreview\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "feature_column_cleanup = feature_column + '_cleanup'\n",
    "# apply preprocessing operations on the text\n",
    "def prepare_text(data, feature_column):\n",
    "    data.loc[:, [feature_column_cleanup]] = data[feature_column].apply(tp.preprocess_text)\n",
    "    return data\n",
    "    \n",
    "\n",
    "X_train = prepare_text(X_train, feature_column)\n",
    "X_test = prepare_text(X_test, feature_column)\n",
    "\n",
    "feature_column = feature_column_cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47998, 7761)\n",
      "(12000, 7761)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "# bag of words + tfidf on text\n",
    "vectorizer = CountVectorizer()\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "X_train_counts = vectorizer.fit_transform(X_train[feature_column_cleanup])\n",
    "X_train_tfidf = transformer.fit_transform(X_train_counts)\n",
    "\n",
    "X_test_counts = vectorizer.transform(X_test[feature_column_cleanup])\n",
    "X_test_tfidf = transformer.transform(X_test_counts)\n",
    "\n",
    "print(X_train_tfidf.shape)\n",
    "print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "models_dict = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=100000),\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(model, X, Y):\n",
    "    metrics_dict = {}\n",
    "    y_pred = model.predict(X)\n",
    "    metrics_dict['accuracy'] = accuracy_score(Y, y_pred)\n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics_dictr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-4f6efc8c2caf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodels_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-809fb11df7e5>\u001b[0m in \u001b[0;36mcompute_metrics\u001b[1;34m(model, X, Y)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmetrics_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmetrics_dictr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics_dictr' is not defined"
     ]
    }
   ],
   "source": [
    "models_results = {}\n",
    "\n",
    "for label, model in models_dict.items():\n",
    "    # fit and test the model\n",
    "    model.fit(X_train_tfidf, Y_train)\n",
    "    models_results[label] = compute_metrics(model, X_test_tfidf, Y_test)\n",
    "    \n",
    "print(models_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "\n",
    "def plot_bar(results_dict, title, ylabel):\n",
    "    plt.bar(results_dict.keys(), results_dict.values())\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=30)\n",
    "    plt.ylim((0,1))\n",
    "    plt.show()\n",
    "\n",
    "metrics_dict = {}\n",
    "\n",
    "for label, results in models_results.items():\n",
    "    for metric, val in results.items():\n",
    "        metrics_dict[f\"{label}_{metric}\"] = val\n",
    "        \n",
    "plot_bar(metrics_dict, \"Accuracies plot for score prediction\", \"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the most important words at each score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N_WORDS = 5\n",
    "\n",
    "def get_top_words_score(clf_pipeline, TOP_N):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    top_words = {}\n",
    "    for i, score in enumerate(set(Y_test)):\n",
    "        # get the TOP_N sorted (desc) by their coefficient of importance in the classifier\n",
    "        top = np.argsort(models_dict['reg'].coef_[i])[-TOP_N_WORDS:]\n",
    "        top_words[score] = list(feature_names[word_id] for word_id in top)\n",
    "        \n",
    "    return top_words\n",
    "\n",
    "top_words = get_top_words_score(text_clf, TOP_N = TOP_N_WORDS)\n",
    "for score, words in top_words.items():\n",
    "    print(f\"[Score = {score}] : {words}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
